---
title: "NUTS, AutoDiff and odin"
author: "Marc Baguelin"
format:
  revealjs:
    footer: "[NUTS, AutoDiff and odin](https://www.imperial.ac.uk/people/m.baguelin)"
    slide-number: c/t
bibliography: papers_autodiff.bib
---

# Setting up model

## Set up

  Compile SIR model with autodiff set in
```{r compile-model}
#| echo: TRUE
#| # Create generator for dust model
gen <- odin.dust::odin_dust("models/sir_adjoint.R")
```

## Set up the particle filter
```{r set-up-particle-filter}
#| echo: TRUE
# Create dataset
incidence <- read.csv("data/incidence.csv")
incidence <- data.frame(
  time = incidence$day * 4,
  cases_observed = incidence$cases)

# Create set of parameters
pars <- list(beta = 0.25, gamma = 0.1, I0 = 1)

# Set up the data for the particle filter
d_df <- incidence
d_df$t <- 1:100 #rename to respect convention that time should not be called time ;)
pf_data <- mcstate::particle_filter_data(d_df, "t", rate=4, initial_time = 0)

# Creating the filter
filter <- mcstate::particle_deterministic$new(data=pf_data, gen, compare = NULL)

# Running the filter for likelihood estimation
filter$run(pars = pars)
```

## Run mcmc

```{r run-mcmc, cache=TRUE}
#| echo: TRUE
beta <- mcstate::pmcmc_parameter("beta", 0.2, min = 0)
gamma <- mcstate::pmcmc_parameter("gamma", 0.1, min = 0, prior = function(p)
  dgamma(p, shape = 1, scale = 0.2, log = TRUE))
I0 <- mcstate::pmcmc_parameter("I0", 1, min = 0)

proposal_matrix <- diag(0.1, 3)
proposal_matrix <- matrix(c(0.0002123093,0.0001906685,-0.0270819864,0.0001906685,0.0001908083,-0.0211008465,-0.0270819864,-0.0211008465,5.30085662), ncol=3)
mcmc_pars <- mcstate::pmcmc_parameters$new(list(beta = beta, gamma = gamma, I0 = I0),
                                           proposal_matrix)
n_steps <- 5000
control <- mcstate::pmcmc_control(
  n_steps,
  save_state = TRUE,
  save_trajectories = TRUE,
  progress = TRUE)
pmcmc_run <- mcstate::pmcmc(mcmc_pars, filter, control = control)
```

## Plot result
```{r plot-mcmc}
plot(log(pmcmc_run$pars[-(1:50),1]),log(pmcmc_run$pars[-(1:50),2]),
     xlim=range(log(pmcmc_run$pars[-(1:50),1]))+c(-2,2),
     ylim=range(log(pmcmc_run$pars[-(1:50),2]))+c(-2,2),
     col="red")
```

## Run gradient
```{r run-gradient}
#| echo: TRUE
# Set up the data to attach to dust model
d <- dust::dust_data(incidence)

# Create new deterministic model with data attached
mod <- gen$new(pars, 0, 1, deterministic = TRUE)
mod$set_data(d)

# Running the likelihood evaluation using the odin model, compare and data
mod$run_adjoint()
```

## This gives same result that simulating the model
```{r}
# Simulating the model and calculating the likelihood based on this
mod$update_state(time = 0)
y <- mod$simulate(c(1:100)*4)
sum(dpois(x = incidence$cases_observed, lambda = y[mod$info()$index$cases_inc,1,], log = TRUE))
```

## Find epsilon

```{r useful-functions}
compute_gradient <- function(mod, theta, trans, pd_trans, t = 0){
  pars <- trans(theta)
  mod$update_state(pars, time = t)
  res_adj <- mod$run_adjoint()
  list(log_likelihood = res_adj$log_likelihood,
       gradient = pd_trans(theta)*res_adj$gradient)
}

hamiltonian <- function(theta, r, mod, g, dg){
  #Note that we only need the likelihood here so no need to also calculate
  #the gradient as we do here
  sum(r^2) / 2  - compute_gradient(mod, theta, g, dg)$log_likelihood
}

# perform 1 leafrog integration of step epsilon
leapfrog <- function(mod, current_theta, current_r, epsilon, g, dg){
  # initialise to the current value of theta and r
  theta <- current_theta
  r <- current_r
  # Make a half step for momentum
  r <- r + epsilon * compute_gradient(mod, theta, g, dg)$gradient / 2
  # Make a full step for theta
  theta <- theta + epsilon * r
  # Make a half step for momentum
  r <- r + epsilon * compute_gradient(mod, theta, g, dg)$gradient / 2
  return(list(theta = theta, r = r))
}

# function from the NUTS paper
# the NUTS paper fix the initial epsilon value to 1,
# in practice this can lead to very big leaps
# here it is given by user
# and generate NaN
find_epsilon1 <- function(mod, theta, g, dg, init_eps){
  epsilon <- init_eps
  r <- rnorm(length(theta),0,1)
  theta_r_prop <- leapfrog(mod, theta, r, epsilon, g, dg)
  if(exp(hamiltonian(theta, r, mod, g, dg)-
         hamiltonian(theta_r_prop$theta,
                     theta_r_prop$r, mod, g, dg)) > 0.5) a <- 1 else a <- -1
  while(exp(a*(hamiltonian(theta,
                           r, mod, g, dg) -hamiltonian(theta_r_prop$theta,
                             theta_r_prop$r, mod, g, dg))) > 2^-a)
  {
    epsilon <- 2^a*epsilon
    theta_r_prop <- leapfrog(mod, theta, r, epsilon, g, dg)
  }
  epsilon
}

g <- function(theta) {as.list(exp(theta))}
dg <- function(theta) {exp(theta)}
theta <- log(unlist(pars))
epsilon0 <- find_epsilon1(mod, theta, g, dg, 0.0001)
```

## Gradient descent

```{r gradient-descent}
#Test the gradient function

plot(log(pmcmc_run$pars[-(1:50),1]),log(pmcmc_run$pars[-(1:50),2]),
     xlim=range(log(pmcmc_run$pars[-(1:50),1]))+c(-1,1),
     ylim=range(log(pmcmc_run$pars[-(1:50),2]))+c(-1,1),
     col="red")
points(theta[1], theta[2], pch=19, col="blue")

for(i in 1:10000)
{
  theta_next <- theta + epsilon0/1000 * compute_gradient(mod, theta, g, dg)$gradient
  lines(c(theta[1],theta_next[1]),c(theta[2],theta_next[2]))
  theta <- theta_next
}
```

## HMC

```{r HMC}
#Test HMC is working with leapfrog integrator
g <- function(theta) {as.list(exp(theta))}
dg <- function(theta) {exp(theta)}
current_theta <- log(unlist(pars))
plot(log(pmcmc_run$pars[-(1:50),1]),log(pmcmc_run$pars[-(1:50),2]),
     xlim=range(log(pmcmc_run$pars[-(1:50),1]))+c(-1,1),
     ylim=range(log(pmcmc_run$pars[-(1:50),2]))+c(-1,1),
     col="red")
points(current_theta[1], current_theta[2], pch=19, col="blue")

h_seq <- NULL
K_seq <- NULL
U_seq <- NULL
L <- 3
for(k in 1:2000){
  current_r <- rnorm(length(theta),0,1)
  theta <- current_theta
  r <- current_r
  for(i in 1:L)
  {
    theta_r_prop <- leapfrog(mod, theta, r, epsilon0/5, g, dg)
    lines(c(theta[1],theta_r_prop$theta[1]),c(theta[2],theta_r_prop$theta[2]))
    theta <- theta_r_prop$theta
    r <- theta_r_prop$r
  }
  current_U <- -compute_gradient(mod, current_theta, g, dg)$log_likelihood
  current_K <- sum(current_r^2) / 2
  proposed_U <- -compute_gradient(mod, theta, g, dg)$log_likelihood
  proposed_K <- sum(r^2) / 2
  #browser()
  if (log(runif(1)) < current_U-proposed_U+current_K-proposed_K)
    current_theta <- theta # accept
  h_seq <- c(h_seq,hamiltonian(current_theta, current_r, mod, g, dg))
  K_seq <- c(K_seq, sum(current_r^2) / 2)
  U_seq <- c(U_seq, - compute_gradient(mod, current_theta, g, dg)$log_likelihood)
}
```

## HMC is a jigged descent

::: {.incremental}
- Far from the mode, gradient descent dominates the dynamics, because potential energy is high
- Near the mode, random momentum generation allows to explore the distribution
:::

## Recursive tree building

```{r recursive-tree-function}
#| echo: TRUE
build_tree <- function(theta, r, u, v, j, epsilon, theta_0, r_0, mod, g, dg, delta = 1000)
{
  if(j==0) {
    # base case, one leapfrog in direction v
    theta_r_prop <- leapfrog(mod, theta, r, v*epsilon, g, dg)
    H_prop <- hamiltonian(theta_r_prop$theta, theta_r_prop$r, mod, g, dg)
    H_0 <- hamiltonian(theta_0, r_0, mod, g, dg)
    n <- as.integer(u <= exp(-H_prop))
    #lines(c(theta["beta"],theta_r_prop$theta["beta"]),c(theta["gamma"],theta_r_prop$theta["gamma"]),col=grey(.6))
    #points(theta_r_prop$theta["beta"],theta_r_prop$theta["gamma"], col=grey(.6))
    s <- u < exp(delta - H_prop)
    return(list(theta_minus = theta_r_prop$theta,
           r_minus = theta_r_prop$r,
           theta_plus = theta_r_prop$theta,
           r_plus = theta_r_prop$r,
           theta_prop = theta_r_prop$theta,
           n_prop = n,
           s_prop = s,
           alpha = min(1, exp(H_0-H_prop)),
           n_alpha = 1)
    )
  } else { #j>0
    result_list <- build_tree(theta, r, u, v, j-1, epsilon, theta_0, r_0, mod, g, dg, delta)
    if(result_list$s_prop){ # continue the tree unless stop condition is reached
      if(v==-1){
        alternative_list <- build_tree(result_list$theta_minus, result_list$r_minus,
                               u, v, j-1, epsilon, theta_0, r_0, mod, g, dg, delta)
        result_list$theta_minus <- alternative_list$theta_minus
        result_list$r_minus <- alternative_list$r_minus
      } else { #v==1
        alternative_list <- build_tree(result_list$theta_plus, result_list$r_plus,
                               u, v, j-1, epsilon, theta_0, r_0, mod, g, dg, delta)
        result_list$theta_plus <- alternative_list$theta_plus
        result_list$r_plus <- alternative_list$r_plus
      }
      sum_n_prop <- result_list$n_prop+alternative_list$n_prop
      if(sum_n_prop > 0)
        if(runif(1)<alternative_list$n_prop/sum_n_prop)
          result_list$theta_prop <- alternative_list$theta_prop
      result_list$alpha <- result_list$alpha + alternative_list$alpha
      result_list$n_alpha <- result_list$n_alpha + alternative_list$n_alpha
      result_list$s_prop <- alternative_list$s_prop &
        ((result_list$theta_plus-result_list$theta_minus)%*%result_list$r_minus >= 0) &
        ((result_list$theta_plus-result_list$theta_minus)%*%result_list$r_plus >= 0)
      result_list$n_prop <- sum_n_prop
    }
    return(result_list)
  }
}
```

## NUTS step

```{r NUTS_step_function}
#| echo: TRUE
NUTS_step <- function(theta, epsilon, mod, g, dg, D_max){
  theta_prop <- theta
  r0 <- rnorm(length(theta),0,1)
  u <- runif(1)*exp(-hamiltonian(theta, r0, mod, g, dg))
  tree_list <- list(theta_minus = theta,
                    r_minus = r0,
                    theta_plus = theta,
                    r_plus = r0
  )
  j <- 0
  n <- 1
  s <- TRUE
  while(s){
    v <- sample(c(-1,1),1)
    if(v==-1){
      tree_list <- build_tree(tree_list$theta_minus, tree_list$r_minus,
                              u, v, j, epsilon, theta, r0, mod, g, dg, D_max)
    } else {
      tree_list <- build_tree(tree_list$theta_plus, tree_list$r_plus,
                              u, v, j, epsilon, theta, r0, mod, g, dg, D_max)
    }
    if(tree_list$s_prop)
      if(runif(1)<min(1,tree_list$n_prop/n))
        theta_prop <- tree_list$theta_prop
    n <- n + tree_list$n_prop
    s <- tree_list$s_prop &
      ((tree_list$theta_plus-tree_list$theta_minus)%*%tree_list$r_minus >= 0) &
      ((tree_list$theta_plus-tree_list$theta_minus)%*%tree_list$r_plus >= 0)
    j <- j+1
  }
  list(theta_prop=theta_prop, j=j, s=s, n=n, theta_minus=tree_list$theta_minus, theta_plus=tree_list$theta_plus)
}
```

## NUTS algorithm

```{r run-NUTS-chain}
#| echo: TRUE
theta0 <- log(unlist(pars))
M <- 5000
M_adapt <- 100
D_max <- 1000
epsilon0 <- find_epsilon1(mod, theta0, g, dg, 0.0001)
mu <- log(10*epsilon0)/10
theta_m <- matrix(rep(theta0, M+1), ncol = length(theta0), byrow = TRUE)
colnames(theta_m) <- names(theta0)

for(i in 1:M)
{
  res <- NUTS_step(theta_m[i,], epsilon0, mod, g, dg, D_max)
  theta_m[i+1,] <- res$theta_prop
}

```

## NUTS algorithm

```{r plot-NUTS-samples}
plot(log(pmcmc_run$pars[-(1:50),1]),log(pmcmc_run$pars[-(1:50),2]),
     xlim=range(log(pmcmc_run$pars[-(1:50),1]))+c(-2,2),
     ylim=range(log(pmcmc_run$pars[-(1:50),2]))+c(-2,2),
     col="red")
points(current_theta[1], current_theta[2], pch=19, col="blue")

points(theta_m[-(1:50),1], theta_m[-(1:50),2], col="orange", pch=19)

```

## NUTS algorithm

```{r plot-NUTS-chain}
plot(theta_m[-(1:50),1])
```
