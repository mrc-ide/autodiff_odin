@inproceedings{Chen2018,
abstract = {We introduce a new family of deep neural network models. Instead of specifying a discrete sequence of hidden layers, we parameterize the derivative of the hidden state using a neural network. The output of the network is computed using a black-box differential equation solver. These continuous-depth models have constant memory cost, adapt their evaluation strategy to each input, and can explicitly trade numerical precision for speed. We demonstrate these properties in continuous-depth residual networks and continuous-time latent variable models. We also construct continuous normalizing flows, a generative model that can train by maximum likelihood, without partitioning or ordering the data dimensions. For training, we show how to scalably backpropagate through any ODE solver, without access to its internal operations. This allows end-to-end training of ODEs within larger models.},
author = {Chen, Ricky T.Q. and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David},
booktitle = {Advances in Neural Information Processing Systems},
issn = {10495258},
pages = {6571--6583},
publisher = {Neural information processing systems foundation},
title = {{Neural ordinary differential equations}},
volume = {2018-December},
year = {2018}
}

@book{AndreasGriewank2008,
abstract = {Algorithmic, or automatic, differentiation (AD) is a growing area of theoretical research and software development concerned with the accurate and efficient evaluation of derivatives for function evaluations given as computer programs. The resulting derivative values are useful for all scientific computations that are based on linear, quadratic, or higher order approximations to nonlinear scalar or vector functions. This second edition covers recent developments in applications and theory, including an elegant NP completeness argument and an introduction to scarcity. There is also added material on checkpointing and iterative differentiation. To improve readability the more detailed analysis of memory and complexity bounds has been relegated to separate, optional chapters. The book consists of: a stand-alone introduction to the fundamentals of AD and its software; a thorough treatment of methods for sparse problems; and final chapters on program-reversal schedules, higher derivatives, nonsmooth problems and iterative processes.},
archivePrefix = {arXiv},
arxivId = {arXiv:1502.05767},
author = {{Andreas Griewank}, Andrea Walther},
booktitle = {SIAM - Society for Industrial and Applied Mathematic},
eprint = {arXiv:1502.05767},
isbn = {0898714516 (pbk.)},
issn = {0949-1775},
keywords = {Algorithmic Differentiation,Automatic Differentiation},
pages = {438},
pmid = {8384989},
title = {{Evaluating Derivatives Principles and Techniques of Algorithmic Differentiation}},
volume = {2},
year = {2008}
}

@incollection{neal_mcmc_2011,
	title = {{MCMC} using hamiltonian dynamics},
	isbn = {978-1-4200-7942-5},
	abstract = {Hamiltonian dynamics can be used to produce distant proposals for the Metropolis algorithm, thereby avoiding the slow exploration of the state space that results from the diffusive behaviour of simple random-walk proposals. Though originating in physics, Hamiltonian dynamics can be applied to most problems with continuous state spaces by simply introducing fictitious "momentum" variables. A key to its usefulness is that Hamiltonian dynamics preserves volume, and its trajectories can thus be used to define complex mappings without the need to account for a hard-to-compute Jacobian factor-a property that can be exactly maintained even when the dynamics is approximated by discretizing time. In this review, I discuss theoretical and practical aspects of Hamiltonian Monte Carlo, and present some of its variations, including using windows of states for deciding on acceptance or rejection, computing trajectories using fast approximations, tempering during the course of a trajectory to handle isolated modes, and shortcut methods that prevent useless trajectories from taking much computation time.},
	urldate = {2022-08-25},
	booktitle = {Handbook of {Markov} {Chain} {Monte} {Carlo}},
	author = {Neal, Radford M},
	year = {2011},
	doi = {10.1201/b10905-6},
	note = {arXiv: 1206.1901},
	keywords = {()},
	pages = {113--162},
}

@article{hoffman_no-u-turn_2014,
	title = {The {No}-{U}-{Turn} {Sampler}: {Adaptively} {Setting} {Path} {Lengths} in {Hamiltonian} {Monte} {Carlo}},
	volume = {15},
	url = {http://mcmc-jags.sourceforge.net},
	abstract = {Hamiltonian Monte Carlo (HMC) is a Markov chain Monte Carlo (MCMC) algorithm that avoids the random walk behavior and sensitivity to correlated parameters that plague many MCMC methods by taking a series of steps informed by first-order gradient information. These features allow it to converge to high-dimensional target distributions much more quickly than simpler methods such as random walk Metropolis or Gibbs sampling. However, HMC's performance is highly sensitive to two user-specified parameters: a step size and a desired number of steps L. In particular, if L is too small then the algorithm exhibits undesirable random walk behavior, while if L is too large the algorithm wastes computation. We introduce the No-U-Turn Sampler (NUTS), an extension to HMC that eliminates the need to set a number of steps L. NUTS uses a recursive algorithm to build a set of likely candidate points that spans a wide swath of the target distribution, stopping automatically when it starts to double back and retrace its steps. Empirically, NUTS performs at least as efficiently as (and sometimes more efficiently than) a well tuned standard HMC method, without requiring user intervention or costly tuning runs. We also derive a method for adapting the step size parameter on the fly based on primal-dual averaging. NUTS can thus be used with no hand-tuning at all, making it suitable for applications such as BUGS-style automatic inference engines that require efficient "turnkey" samplers.},
	urldate = {2022-08-26},
	journal = {Journal of Machine Learning Research},
	author = {Hoffman, Matthew D and Gelman, Andrew},
	year = {2014},
	keywords = {Markov chain Monte Carlo, Bayesian inference, Hamiltonian Monte Carlo, adaptive Monte Carlo, dual averaging},
	pages = {1351--1381},
}

@misc{scibior_differentiable_2021,
	title = {Differentiable {Particle} {Filtering} without {Modifying} the {Forward} {Pass}},
	url = {http://arxiv.org/abs/2106.10314},
	abstract = {Particle filters are not compatible with automatic differentiation due to the presence of discrete resampling steps. While known estimators for the score function, based on Fisher's identity, can be computed using particle filters, up to this point they required manual implementation. In this paper we show that such estimators can be computed using automatic differentiation, after introducing a simple correction to the particle weights. This correction utilizes the stop-gradient operator and does not modify the particle filter operation on the forward pass, while also being cheap and easy to compute. Surprisingly, with the same correction automatic differentiation also produces good estimators for gradients of expectations under the posterior. We can therefore regard our method as a general recipe for making particle filters differentiable. We additionally show that it produces desired estimators for second-order derivatives and how to extend it to further reduce variance at the expense of additional computation.},
	urldate = {2023-08-21},
	publisher = {arXiv},
	author = {Åšcibior, Adam and Wood, Frank},
	month = oct,
	year = {2021},
	note = {arXiv:2106.10314 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 24 pages, 3 figures},
}

@misc{schulman_gradient_2016,
	title = {Gradient {Estimation} {Using} {Stochastic} {Computation} {Graphs}},
	url = {http://arxiv.org/abs/1506.05254},
	abstract = {In a variety of problems originating in supervised, unsupervised, and reinforcement learning, the loss function is defined by an expectation over a collection of random variables, which might be part of a probabilistic model or the external world. Estimating the gradient of this loss function, using samples, lies at the core of gradient-based learning algorithms for these problems. We introduce the formalism of stochastic computation graphs---directed acyclic graphs that include both deterministic functions and conditional probability distributions---and describe how to easily and automatically derive an unbiased estimator of the loss function's gradient. The resulting algorithm for computing the gradient estimator is a simple modification of the standard backpropagation algorithm. The generic scheme we propose unifies estimators derived in variety of prior work, along with variance-reduction techniques therein. It could assist researchers in developing intricate models involving a combination of stochastic and deterministic operations, enabling, for example, attention, memory, and control actions.},
	urldate = {2023-08-21},
	publisher = {arXiv},
	author = {Schulman, John and Heess, Nicolas and Weber, Theophane and Abbeel, Pieter},
	month = jan,
	year = {2016},
	note = {arXiv:1506.05254 [cs]},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: Advances in Neural Information Processing Systems 28 (NIPS 2015)},
}

@misc{betancourt_conceptual_2018,
	title = {A {Conceptual} {Introduction} to {Hamiltonian} {Monte} {Carlo}},
	url = {http://arxiv.org/abs/1701.02434},
	doi = {10.48550/arXiv.1701.02434},
	abstract = {Hamiltonian Monte Carlo has proven a remarkable empirical success, but only recently have we begun to develop a rigorous understanding of why it performs so well on difficult problems and how it is best applied in practice. Unfortunately, that understanding is confined within the mathematics of differential geometry which has limited its dissemination, especially to the applied communities for which it is particularly important. In this review I provide a comprehensive conceptual account of these theoretical foundations, focusing on developing a principled intuition behind the method and its optimal implementations rather of any exhaustive rigor. Whether a practitioner or a statistician, the dedicated reader will acquire a solid grasp of how Hamiltonian Monte Carlo works, when it succeeds, and, perhaps most importantly, when it fails.},
	urldate = {2023-09-01},
	publisher = {arXiv},
	author = {Betancourt, Michael},
	month = jul,
	year = {2018},
	note = {arXiv:1701.02434 [stat]},
	keywords = {Statistics - Methodology},
	annote = {Comment: 60 pages, 42 figures},
}

@article{Girolami2011,
	title = {Riemann manifold {Langevin} and {Hamiltonian} {Monte} {Carlo} methods},
	volume = {73},
	issn = {13697412},
	url = {http://doi.wiley.com/10.1111/j.1467-9868.2010.00765.x},
	doi = {10.1111/j.1467-9868.2010.00765.x},
	number = {2},
	urldate = {2012-01-30},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Girolami, Mark and Calderhead, Ben},
	month = mar,
	year = {2011},
	pages = {123--214},
}

@article{livingstone_kinetic_2019,
	title = {Kinetic energy choice in {Hamiltonian}/hybrid {Monte} {Carlo}},
	volume = {106},
	issn = {0006-3444},
	url = {https://doi.org/10.1093/biomet/asz013},
	doi = {10.1093/biomet/asz013},
	abstract = {We consider how different choices of kinetic energy in Hamiltonian Monte Carlo affect algorithm performance. To this end, we introduce two quantities which can be easily evaluated, the composite gradient and the implicit noise. Results are established on integrator stability and geometric convergence, and we show that choices of kinetic energy that result in heavy-tailed momentum distributions can exhibit an undesirable negligible moves property, which we define. A general efficiency-robustness trade-off is outlined, and implementations which rely on approximate gradients are also discussed. Two numerical studies illustrate our theoretical findings, showing that the standard choice which results in a Gaussian momentum distribution is not always optimal in terms of either robustness or efficiency.},
	number = {2},
	urldate = {2023-09-07},
	journal = {Biometrika},
	author = {Livingstone, S and Faulkner, M F and Roberts, G O},
	month = jun,
	year = {2019},
	pages = {303--319},
}

